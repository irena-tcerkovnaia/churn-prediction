{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot text on a graph\n",
    "\n",
    "def plot_text(ax: plt.Axes):\n",
    "    \"\"\"\n",
    "    text on barplot\n",
    "    \"\"\"\n",
    "    for p in ax.patches:\n",
    "        percentage = '{:.1f}%'.format(p.get_height())\n",
    "        ax.annotate(\n",
    "            percentage,  # text\n",
    "            # coordinate xy\n",
    "            (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "            # center\n",
    "            ha='center',\n",
    "            va='center',\n",
    "            xytext=(0, 10),\n",
    "            # offset point\n",
    "            textcoords='offset points',\n",
    "            fontsize=14)\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def barplot_group_by_category(df_data: pd.DataFrame, col_main: str, col_group: str,\n",
    "                              title: str) -> None:\n",
    "    \"\"\"\n",
    "    build barplot with normalized data and graph data annotations\n",
    "\n",
    "    highligting target variable by variable\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    data = (df_data.groupby([col_main])[col_group].value_counts(normalize=True).rename(\n",
    "        'percentage').mul(100).reset_index().sort_values(col_main))\n",
    "\n",
    "    ax = sns.barplot(x=col_main,\n",
    "                     y=\"percentage\",\n",
    "                     hue=col_group,\n",
    "                     data=data,\n",
    "                     palette='rocket')\n",
    "\n",
    "    for p in ax.patches:\n",
    "        percentage = '{:.1f}%'.format(p.get_height())\n",
    "        ax.annotate(\n",
    "            percentage,\n",
    "            (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "            ha='center',\n",
    "            va='center',\n",
    "            xytext=(0, 7),\n",
    "            textcoords='offset points',\n",
    "            fontsize=12)\n",
    "\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.ylabel('Percentage', fontsize=14)\n",
    "    plt.xlabel(col_main, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def barplot_group_within_targetvar(df_data: pd.DataFrame, col_main: str, col_group: str,\n",
    "                                   title: str) -> None:\n",
    "    \"\"\"\n",
    "    build barplot with normalized data and graph data annotations\n",
    "\n",
    "    highligting proportion of variable within target group\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    data = (df_data.groupby([col_group])[col_main].value_counts(normalize=True).rename(\n",
    "        'percentage').mul(100).reset_index().sort_values(col_group))\n",
    "\n",
    "    ax = sns.barplot(x=col_main,\n",
    "                     y=\"percentage\",\n",
    "                     hue=col_group,\n",
    "                     data=data,\n",
    "                     palette='rocket')\n",
    "\n",
    "    for p in ax.patches:\n",
    "        percentage = '{:.1f}%'.format(p.get_height())\n",
    "        ax.annotate(\n",
    "            percentage,\n",
    "            (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "            ha='center',\n",
    "            va='center',\n",
    "            xytext=(0, 7),\n",
    "            textcoords='offset points',\n",
    "            fontsize=12)\n",
    "\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.ylabel('Percentage', fontsize=14)\n",
    "    plt.xlabel(col_main, fontsize=14)\n",
    "    plt.show()"
   ],
   "id": "7fd46750f0d59acd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def barplot_group_within_targetvar(df_data: pd.DataFrame, col_main: str, col_group: str,\n",
    "                  title: str) -> None:\n",
    "    \"\"\"\n",
    "    build barplot with normalized data and graph data annotations\n",
    "\n",
    "    highligting proportion of variable within target group\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    data = (df_data.groupby([col_group])[col_main].value_counts(normalize=True).rename(\n",
    "            'percentage').mul(100).reset_index().sort_values(col_group))\n",
    "\n",
    "    ax = sns.barplot(x=col_main,\n",
    "                     y=\"percentage\",\n",
    "                     hue=col_group,\n",
    "                     data=data,\n",
    "                     palette='rocket')\n",
    "\n",
    "    for p in ax.patches:\n",
    "        percentage = '{:.1f}%'.format(p.get_height())\n",
    "        ax.annotate(\n",
    "            percentage,\n",
    "            (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "            ha='center',\n",
    "            va='center',\n",
    "            xytext=(0, 7),\n",
    "            textcoords='offset points',\n",
    "            fontsize=12)\n",
    "\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.ylabel('Percentage', fontsize=14)\n",
    "    plt.xlabel(col_main, fontsize=14)\n",
    "    plt.show()"
   ],
   "id": "f0bc855be318fc9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# checking for multicollinearity - VIF (Variance Inflation Factor)\n",
    "# tells you how much the variance of a regression coefficient is inflated due to multicollinearity\n",
    "\n",
    "def compute_vif(df):\n",
    "    vif_data = []\n",
    "    X = df.dropna()\n",
    "    for i in range(X.shape[1]):\n",
    "        y = X.iloc[:, i]\n",
    "        X_other = X.drop(X.columns[i], axis=1)\n",
    "\n",
    "        model = LinearRegression().fit(X_other, y)\n",
    "        r2 = model.score(X_other, y)\n",
    "        vif = 1 / (1 - r2) if r2 < 1 else float('inf')\n",
    "\n",
    "        vif_data.append({'Variable': X.columns[i], 'VIF': vif})\n",
    "\n",
    "    return pd.DataFrame(vif_data)"
   ],
   "id": "225c6698681305c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# chi-square test and Cramer's V functions for categorical variables association\n",
    "\n",
    "def cramers_v(confusion_matrix):\n",
    "    \"\"\"Compute Cramér's V (strength of association) from a confusion matrix.\"\"\"\n",
    "    chi2 = stats.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "\n",
    "def categorical_assoc_with_churn(df, churn_col='Churn'):\n",
    "    \"\"\"\n",
    "    For each categorical feature in df (excluding churn_col),\n",
    "    run Chi-square test + Cramér's V against churn.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Loop over categorical columns\n",
    "    for col in df.select_dtypes(include=['object', 'category']).columns:\n",
    "        if col == churn_col:\n",
    "            continue  # skip target\n",
    "\n",
    "        contingency_table = pd.crosstab(df[churn_col], df[col])\n",
    "\n",
    "        # Chi-square\n",
    "        chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "        # Cramer's V\n",
    "        cv = cramers_v(contingency_table)\n",
    "\n",
    "        results.append({\n",
    "            'Feature': col,\n",
    "            'Chi2': chi2,\n",
    "            'p_value': p,\n",
    "            'Cramers_V': cv\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).sort_values('Cramers_V', ascending=False)\n"
   ],
   "id": "c01e90858e49a592"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# evaluation metrics : Regression & Classification problems\n",
    "\n",
    "\n",
    "\n",
    "def r2_adjusted(y_true: np.ndarray, y_pred: np.ndarray,\n",
    "                X_test: np.ndarray) -> float:\n",
    "\n",
    "    N_objects = len(y_true)\n",
    "    N_features = X_test.shape[1]\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return 1 - (1 - r2) * (N_objects - 1) / (N_objects - N_features - 1)\n",
    "\n",
    "\n",
    "def mpe(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Mean percentage error\"\"\"\n",
    "    return np.mean((y_true - y_pred) / y_true) * 100\n",
    "\n",
    "\n",
    "def mape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Mean absolute percentage error\"\"\"\n",
    "    return np.mean(np.abs((y_pred - y_true) / y_true)) * 100\n",
    "\n",
    "\n",
    "def wape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Weighted Absolute Percent Error\"\"\"\n",
    "    return np.sum(np.abs(y_pred - y_true)) / np.sum(y_true) * 100\n",
    "\n",
    "\n",
    "def huber_loss(y_true: np.ndarray, y_pred: np.ndarray, delta: float = 1.345):\n",
    "    \"\"\"Huber loss fucntion\"\"\"\n",
    "    assert len(y_true) == len(y_pred), 'difference size of data'\n",
    "    huber_sum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if abs(y_true[i] - y_pred[i]) <= delta:\n",
    "            huber_sum += 0.5 * (y_true[i] - y_pred[i])**2\n",
    "        else:\n",
    "            huber_sum += delta * (abs(y_true[i] - y_pred[i]) - 0.5 * delta)\n",
    "    huber_sum /= len(y_true)\n",
    "    return huber_sum\n",
    "\n",
    "\n",
    "def logcosh(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    \"\"\"Log-Cosh loss function\"\"\"\n",
    "    return np.sum(np.log(np.cosh(y_true - y_pred)))\n",
    "\n",
    "\n",
    "def rmsle(y_true: np.ndarray, y_pred: np.ndarray) -> np.float64:\n",
    "    \"\"\"\n",
    "    The Root Mean Squared Log Error (RMSLE) metric\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_metrics_regression(y_test: np.ndarray,\n",
    "                           y_pred: np.ndarray,\n",
    "                           X_test: np.ndarray,\n",
    "                           name: str = None,\n",
    "                           delta: float = 1.345):\n",
    "    \"\"\"generate table with metrics for regression problem\"\"\"\n",
    "    df_metrics = pd.DataFrame()\n",
    "\n",
    "    df_metrics['model'] = [name]\n",
    "\n",
    "    df_metrics['MAE'] = mean_absolute_error(y_test, y_pred)\n",
    "    df_metrics['MSE'] = mean_squared_error(y_test, y_pred)\n",
    "    df_metrics['RMSE'] = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    df_metrics['RMSLE'] = rmsle(y_test, y_pred)\n",
    "    df_metrics['R2 adjusted'] = r2_adjusted(y_test, y_pred, X_test)\n",
    "    # df_metrics['Huber_loss'] = huber_loss(y_test, y_pred, delta)\n",
    "    # df_metrics['Logcosh'] = logcosh(y_test, y_pred)\n",
    "    df_metrics['MPE_%'] = mpe(y_test, y_pred)\n",
    "    df_metrics['MAPE_%'] = mape(y_test, y_pred)\n",
    "    df_metrics['WAPE_%'] = wape(y_test, y_pred)\n",
    "\n",
    "    return df_metrics\n",
    "\n",
    "\n",
    "def get_metrics_classification(y_test, y_pred, y_score, name):\n",
    "    \"\"\"generate table with metrics for classification problem\"\"\"\n",
    "    df_metrics = pd.DataFrame()\n",
    "\n",
    "    df_metrics['model'] = [name]\n",
    "    df_metrics['Accuracy'] = accuracy_score(y_test, y_pred)\n",
    "    df_metrics['ROC_AUC'] = roc_auc_score(y_test, y_score) #[:, 1])\n",
    "    df_metrics['Precision'] = precision_score(y_test, y_pred)\n",
    "    df_metrics['Recall'] = recall_score(y_test, y_pred)\n",
    "    df_metrics['f1'] = f1_score(y_test, y_pred)\n",
    "    df_metrics['Logloss'] = log_loss(y_test, y_score)\n",
    "\n",
    "    return df_metrics"
   ],
   "id": "1c2b2a97f2d6e489"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def check_overfitting_classification(model, X_train, y_train, X_test, y_test, metric_fun):\n",
    "    \"\"\"\n",
    "   check overfitting for classification\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained classification model.\n",
    "    - X_train: Training features.\n",
    "    - y_train: Training target labels.\n",
    "    - X_test: Test features.\n",
    "    - y_test: Test target labels.\n",
    "    - metric_fun: Metric function (e.g., accuracy_score, f1_score, roc_auc_score).\n",
    "    \"\"\"\n",
    "    # Predict on training and test sets\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calculate metric values\n",
    "    value_train = metric_fun(y_train, y_pred_train)\n",
    "    value_test = metric_fun(y_test, y_pred_test)\n",
    "\n",
    "    # Print results\n",
    "    print(f'{metric_fun.__name__} train: %.3f' % value_train)\n",
    "    print(f'{metric_fun.__name__} test: %.3f' % value_test)\n",
    "    print(f'delta = {(abs(value_train - value_test) / value_test * 100):.1f} %')\n"
   ],
   "id": "ec214bb7e3a736a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Catboost for Classification\n",
    "\n",
    "\n",
    "def objective_lgb(trial, X, y, N_FOLDS, random_state, cat_feat):\n",
    "    params = {\n",
    "\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [300]),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.08797829241393999]),\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.3, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.5,1.0),\n",
    "        \"l2_leaf_reg\": trial.suggest_uniform(\"l2_leaf_reg\", 1e-5, 1e2),\n",
    "        'random_strength': trial.suggest_uniform('random_strength', 10, 50),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\", \"No\"]),\n",
    "        'border_count': trial.suggest_categorical('border_count', [128, 254]),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', [\"SymmetricTree\", \"Depthwise\", \"Lossguide\"]),\n",
    "\n",
    "        'od_wait': trial.suggest_int('od_wait', 500, 2000),\n",
    "        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations', 1, 15),\n",
    "        #\"cat_features\": trial.suggest_categorical(\"cat_features\", [\"cat_features\"])\n",
    "        #\"loss_function\": trial.suggest_categorical(\"loss_function\", [\"MAE\"]),\n",
    "        \"use_best_model\": trial.suggest_categorical(\"use_best_model\", [True]),\n",
    "        \"eval_metric\": trial.suggest_categorical(\"eval_metric\", [\"AUC\"]),\n",
    "        \"random_state\": random_state\n",
    "    }\n",
    "\n",
    "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        params[\"bagging_temperature\"] = trial.suggest_float(\n",
    "            \"bagging_temperature\", 0, 100)\n",
    "    elif params[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        params[\"subsample\"] = trial.suggest_float(\n",
    "            \"subsample\", 0.1, 1, log=True)\n",
    "\n",
    "    cv = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        train_data = Pool(data=X_train, label=y_train, cat_features=cat_feat)\n",
    "        eval_data = Pool(data=X_test, label=y_test, cat_features=cat_feat)\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_data,\n",
    "                  eval_set=[eval_data],\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        cv_predicts[idx] = roc_auc_score(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_predicts)"
   ],
   "id": "728f337db10477ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def cross_validation_cat(X_train: pd.DataFrame,\n",
    "                         y_train: pd.Series,\n",
    "                         X_test: pd.DataFrame,\n",
    "                         y_test: pd.Series,\n",
    "                         clf,\n",
    "                         params: dict,\n",
    "                         cat_features: list = None,\n",
    "                         eval_metric: str = None,\n",
    "                         early_stop: bool = False,\n",
    "                         early_stopping_rounds: int = 100,\n",
    "                         num_folds: int = 3,\n",
    "                         random_state: int = 10,\n",
    "                         shuffle: bool = True):\n",
    "\n",
    "    \"\"\"using cross-validation for classification problem (catboost base algorithms - no tuning)\"\"\"\n",
    "    \n",
    "    # shuffle - shuffle data before splitting only\n",
    "    folds = KFold(n_splits=num_folds, random_state=random_state, shuffle=shuffle)\n",
    "    score_oof = []\n",
    "    predictions_test = []\n",
    "\n",
    "    for fold, (train_index,\n",
    "               test_index) in enumerate(folds.split(X_train, y_train)):\n",
    "        X_train_, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        y_val_exp = np.exp(y_val) - 1\n",
    "\n",
    "        model = clf(**params)\n",
    "\n",
    "        if early_stop == True:\n",
    "            if eval_metric is None:\n",
    "                model.fit(X_train_,\n",
    "                          y_train_,\n",
    "                          eval_set=[(X_val, y_val)],\n",
    "                          cat_features=cat_features,\n",
    "                          silent=True,\n",
    "                          early_stopping_rounds=early_stopping_rounds)\n",
    "            else:\n",
    "                model.fit(X_train_,\n",
    "                          y_train_,\n",
    "                          eval_set=[(X_val, y_val)],\n",
    "                          eval_metric=eval_metric,\n",
    "                          silent=True,\n",
    "                          cat_features=cat_features,\n",
    "                          early_stopping_rounds=early_stopping_rounds)\n",
    "        else:\n",
    "            model.fit(X_train_, y_train_, cat_features=cat_features)\n",
    "\n",
    "        y_pred_val = model.predict(X_val)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        print(\n",
    "            \"Fold:\", fold + 1,\n",
    "            \"ROC-AUC SCORE %.3f\" % roc_auc_score(y_val, y_pred_val))\n",
    "        print(\"---\")\n",
    "\n",
    "        # oof list\n",
    "        score_oof.append(roc_auc_score(y_val, y_pred_val))\n",
    "        # holdout list\n",
    "        predictions_test.append(y_pred)\n",
    "\n",
    "    return score_oof, predictions_test"
   ],
   "id": "7060295b0d56fb7c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
